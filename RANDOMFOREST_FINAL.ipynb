{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "### Imports ###\n",
    "###############\n",
    "from datetime import datetime \n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import * \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.models as models \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, AveragePooling2D, MaxPooling2D, Flatten, Dense, LSTM, BatchNormalization\n",
    "from tensorflow.keras import regularizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "###########################http://localhost:8888/notebooks/Model/RANDOMFOREST_FINAL.ipynb#\n",
    "### Basic configuration ###\n",
    "###########################\n",
    "\n",
    "# Ignore warnings about deprecated features\n",
    "warnings.simplefilter(action = \"ignore\")\n",
    "\n",
    "# Check the number of available GPUs\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(\"Number of GPUs Available:\", len(physical_devices))\n",
    "\n",
    "# Set if memory growth should be enabled for a PhysicalDevice\n",
    "if physical_devices: tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#### Generation of the score dictionary  ### \n",
    "############################################\n",
    "\n",
    "# Initialize the score dictionary\n",
    "scores = {}\n",
    "# Opening the score csv file\n",
    "with open(\"../scores.csv\", mode = \"r\", encoding = \"utf-8-sig\") as file:\n",
    "  # Reading the csv file\n",
    "  scoreFile = csv.reader(file, delimiter = \";\")\n",
    "  # Save the contents of the CSV file\n",
    "  for lines in scoreFile: \n",
    "    id = lines[0]\n",
    "    score = lines[1]\n",
    "    scores[id] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "### Generation of the locomotion matrix dictionary ###\n",
    "######################################################\n",
    "\n",
    "# Get the list of locomotion data files \n",
    "listLocomotionData = os.listdir(\"../Locomotion\")\n",
    "\n",
    "# Initialize the data dictionary\n",
    "data = {}\n",
    "# Get the list of sensor names\n",
    "sensor_names = pd.read_excel(\"../Locomotion/\" + listLocomotionData[0]).columns\n",
    "\n",
    "# Iterate through the score dictionary\n",
    "for key, value in scores.items(): \n",
    "  # Iterate through the list of locomotion data files \n",
    "  for locomotion in listLocomotionData: \n",
    "    if key in locomotion:\n",
    "      df = pd.read_excel (\"../Locomotion/\" + locomotion)\n",
    "      df = df.dropna(how = \"all\")\n",
    "      df = df.fillna(0)\n",
    "      df = df.to_numpy()\n",
    "      data[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS: 60 ROWS: 502\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "### Set dimensions of the matrices ###\n",
    "######################################\n",
    "\n",
    "# Initialize the number of rows and columns\n",
    "n_rows = []\n",
    "n_columns = 60\n",
    "\n",
    "# Iterate through the data dictionary\n",
    "for key, value in data.items(): \n",
    "  # Save the number of rows of the actual array\n",
    "  n_rows.append(value.shape[0])\n",
    "    \n",
    "# Set the number of rows for all arrays with the maximum number of rows available \n",
    "n_rows = max(n_rows)\n",
    "# Print the number of rows and columns\n",
    "print(\"COLUMNS:\", n_columns, \"ROWS:\", n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cows with class 2:  20\n",
      "Number of cows with class 2.5:  30\n",
      "Number of cows with class 3:  19\n",
      "Number of cows with class 3.5:  5\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "### Generation of matrices and imputation of missing data ###\n",
    "#############################################################\n",
    "\n",
    "# Initialize the feature matrix and the class vector\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Iterate through the data dictionary\n",
    "for key, value in data.items():\n",
    "  \n",
    "  # Build the features matrix\n",
    "  if scores[key] == \"2\" or scores[key] == \"2,5\" or scores[key] == \"3\" or scores[key] == \"3,5\":\n",
    "    matrix = []\n",
    "    for i in range(n_columns):\n",
    "      sequence = []\n",
    "      for j in range(n_rows):\n",
    "        try: sequence.append(float(value[j][i]))\n",
    "        except:sequence.append(float(0))\n",
    "      sequence = np.array(sequence)\n",
    "      matrix.append(sequence)\n",
    "    matrix = np.array(matrix)\n",
    "    X.append(matrix)\n",
    "\n",
    "    # Save the classes\n",
    "    if scores[key] == \"2\": y.append(0)\n",
    "    elif scores[key] == \"2,5\":y.append(1)\n",
    "    elif scores[key] == \"3\":y.append(2)\n",
    "    elif scores[key] == \"3,5\" :y.append(3)\n",
    "    else: pass\n",
    "\n",
    "# Print the distributions of the classes\n",
    "print(\"Number of cows with class 2: \", y.count(0))\n",
    "print(\"Number of cows with class 2.5: \", y.count(1))\n",
    "print(\"Number of cows with class 3: \", y.count(2))\n",
    "print(\"Number of cows with class 3.5: \", y.count(3))\n",
    "\n",
    "# Transform the matrix avec vector to numpy array\n",
    "X = np.array(X)\n",
    "y_array = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances = 74 \n",
      "Number of features per instance = 60 \n",
      "Number of values per feature = 502\n",
      " \n",
      "Matrice = (74, 60, 502)\n",
      "Classes = {0, 1, 2, 3}\n",
      "Example of instance =\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "First value of the first feature of the first instance = 0.0\n",
      "Middle value of the middle feature of the middle instance = 29.043\n",
      "Last value of the last feature of the last instance = 0.0\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "### Get data informations ###\n",
    "#############################\n",
    "\n",
    "n_instances = X.shape[0]\n",
    "n_features = X.shape[1]\n",
    "n_values = X.shape[2]\n",
    "print(\"Number of instances =\", n_instances, \n",
    "      \"\\nNumber of features per instance =\", n_features, \n",
    "      \"\\nNumber of values per feature =\", n_values)\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Matrice =\", X.shape)\n",
    "print(\"Classes =\", set(y))\n",
    "print(\"Example of instance =\\n\", X[0])\n",
    "print(\"First value of the first feature of the first instance =\", X[0][0][0])\n",
    "print(\"Middle value of the middle feature of the middle instance =\", X[int(n_instances / 2)][int(n_features /2)][int(n_values /2)])\n",
    "print(\"Last value of the last feature of the last instance =\", X[n_instances - 1][n_features - 1][n_values - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data:  55\n",
      "Length of validation data:  19\n"
     ]
    }
   ],
   "source": [
    "# construct the training and testing splits\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y_array, stratify = y_array, \n",
    "\ttest_size=0.25, shuffle = True)\n",
    "\n",
    "print(\"Length of training data: \", len(X_train))\n",
    "print(\"Length of validation data: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to perform data augmentation:  616.8316721916199\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "### Perform data augmentation ###\n",
    "#################################\n",
    "\n",
    "import time\n",
    "start = time.time() # Data augmentation takes roughly 10 minutes\n",
    "\n",
    "## ONLY AUGMENT THE TRAINING DATA! \n",
    "\n",
    "# Initialize the feature matrix and the class vector for generated data\n",
    "X_Generated = []\n",
    "y_Generated = []\n",
    "\n",
    "# Set the variation percentage for random noise generation\n",
    "variation_percentage = 5\n",
    "\n",
    "# Iterate through the instances of X\n",
    "for i, x in enumerate(X_train):\n",
    "    \n",
    "    # Set the number of instance to generate balanced dataset (roughly ~2500 instances of each class)\n",
    "    if y_train[i] == 0: n_generated_instances = 2500 // (y_train == 0).sum()\n",
    "    if y_train[i] == 1: n_generated_instances = 2500 // (y_train == 1).sum()\n",
    "    if y_train[i] == 2: n_generated_instances = 2500 // (y_train == 2).sum()\n",
    "    if y_train[i] == 3: n_generated_instances = 2500 // (y_train == 3).sum()\n",
    "    \n",
    "    # Iterate through the inumber of instances to generate\n",
    "    for j in range(int(n_generated_instances)):\n",
    "        # Initialize the vector to save the new matrix\n",
    "        x_Generated = []\n",
    "        # Iterate through the row of the actual instance\n",
    "        for row in x:\n",
    "            # Initialize the vector to save the new row\n",
    "            x_Generated_Row = []\n",
    "            # Iterate through the value of the actual row\n",
    "            for value in row:\n",
    "                # Generate random variation for the instance\n",
    "                random_number = random.random()  * variation_percentage / 100\n",
    "                # Generate boolen to add or remove the variation\n",
    "                boolean = random.randint(0 , 1)\n",
    "                # Save value adding variation\n",
    "                if boolean == 0: x_Generated_Row.append(value + value * random_number)\n",
    "                # Save value removing variation\n",
    "                else: x_Generated_Row.append(value - value * random_number)\n",
    "            # Convert the row vector to numpy array\n",
    "            x_Generated_Row = np.array(x_Generated_Row)\n",
    "            # Save the row vector\n",
    "            x_Generated.append(x_Generated_Row)\n",
    "        # Convert the matrix vector to numpy matrix\n",
    "        x_Generated = np.array(x_Generated)\n",
    "        # Save the generated matrix\n",
    "        X_Generated.append(x_Generated)\n",
    "        # Save the associated classes\n",
    "        y_Generated.append(y_train[i])\n",
    "\n",
    "# Transform the matrix avec vector to numpy array\n",
    "X_Generated = np.array(X_Generated)\n",
    "y_Generated = np.array(y_Generated)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken to perform data augmentation: \", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Matrice:\", X_Generated.shape)\\nprint(\"Classes:\", set(y_Generated))\\nprint(\"Number of targets: \", y_Generated.shape)\\nprint(\"Example of instance:\", X_Generated[0])\\nprint(\"Example of shape of instance:\", X_Generated[0].shape)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################\n",
    "### Display the data informations ###\n",
    "#####################################\n",
    "\n",
    "\"\"\"\n",
    "print(\"Matrice:\", X_Generated.shape)\n",
    "print(\"Classes:\", set(y_Generated))\n",
    "print(\"Number of targets: \", y_Generated.shape)\n",
    "print(\"Example of instance:\", X_Generated[0])\n",
    "print(\"Example of shape of instance:\", X_Generated[0].shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape = (9968, 30120)\n",
      "X_test shape = (19, 30120)\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "### Reshape the data for training ###\n",
    "#####################################\n",
    "\n",
    "#X_Generated = X_train\n",
    "#y_Generated = y_train\n",
    "\n",
    "def flatten_vector(array):\n",
    "    flat_X = []\n",
    "    for i in range(array.shape[0]):\n",
    "        flattened = array[i].flatten()\n",
    "        flat_X.append(flattened)\n",
    "    return np.array(flat_X, dtype=\"float16\")\n",
    "\n",
    "X_Generated = flatten_vector(X_Generated)\n",
    "X_test = flatten_vector(X_test)\n",
    "\n",
    "print(\"X_train shape =\", X_Generated.shape)\n",
    "print(\"X_test shape =\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to finish fitting all models:  13.960999250411987\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "### Random Forest Model Train ###\n",
    "#################################\n",
    "import time\n",
    "start = time.time() # Data augmentation takes roughly 10 minutes\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100, criterion='gini', max_depth=None, bootstrap=True, n_jobs=-1,  random_state=42)\n",
    "model.fit(X_Generated, y_Generated)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken to finish fitting all models: \", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 3 0 0 2 2 1 1 2 3 1 0 2 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "### Random Forest Model Prediction ###\n",
    "######################################\n",
    "target_names = [\"2\", \"2,5\", \"3\", \"3,5\"]\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "#predictions = np.argmax(predictions)\n",
    "true_labels = y_test\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##################################\n",
    "### Random Forest After Grid Search ###\n",
    "##################################\n",
    "\n",
    "# train the classifier\n",
    "Best_RF_model = RandomForestClassifier(**parameters)\n",
    "Best_RF_model.fit(X_Generated, y_Generated)\n",
    "target_names = [\"2\", \"2,5\", \"3\", \"3,5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutating model:  WELFAREAI-RF-5%var-15Oct2021-16h10m25\n"
     ]
    }
   ],
   "source": [
    "# create a filename for the model and save it\n",
    "dateTimeObj = datetime.now().strftime(\"%d%b%Y-%Hh%Mm%S\")\n",
    "filename = \"WELFAREAI-RF-\"+str(variation_percentage)+\"%var-\"+str(dateTimeObj)\n",
    "\n",
    "print(\"Evalutating model: \", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         2.0      0.600     0.600     0.600         5\n",
      "         2.5      0.375     0.375     0.375         8\n",
      "           3      0.000     0.000     0.000         5\n",
      "         3.5      0.000     0.000     0.000         1\n",
      "\n",
      "    accuracy                          0.316        19\n",
      "   macro avg      0.244     0.244     0.244        19\n",
      "weighted avg      0.316     0.316     0.316        19\n",
      "\n",
      " \n",
      "Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEKCAYAAABkEVK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfnElEQVR4nO3de7BdZZnn8e/vnJzcSWI4EUJIuAwRBFogHpFoyUQah5tWaJop6LGkxxkbYcDLSFtla5e2WlDVtjoOcjPdWopyGRAE1CCXBkaYEsyFgBAMBOUSTwIkkJOEXM5lP/PHXoHN8Zyz10nWOmvvvX6fqlXstfe713rebPLkfde73ncpIjAzK5u2ogMwMyuCk5+ZlZKTn5mVkpOfmZWSk5+ZlZKTn5mVkpOfmTU0SRMl/VbSY5KelPTVIcpI0uWS1kp6XNKCescdl0+4ZmaZ2QWcFBHbJHUAD0m6MyIerilzGjA/2d4LXJ38d1hu+ZlZQ4uqbcluR7INnp2xGLg2KfswMEPS7JGO23Qtv86Z7XHw3I6iw8jc6u5ZRYdgozRu4+tFh5Cbrby2MSL2+H/KUz44JTa9OpCq7IrHdz0J7Kx5a0lELKktI6kdWAEcBlwZEY8MOswc4MWa/XXJe+uHO2/TJb+D53bw27vmFh1G5t79TxcWHYKNUueS3xQdQm7ujZ8+vzff3/jqAI/cdWCqsh2zn90ZEV0jlYmIAeBYSTOAn0k6OiKeqCmiob420jGbLvmZWTMIBqKS/VEjNkt6ADgVqE1+64DaVtGBQPdIx/I1PzPLXAAVItVWj6RZSYsPSZOAk4HfDyp2B3BeMup7AtATEcN2ecEtPzPLSYXMWn6zgR8l1/3agJsi4heSLgCIiGuApcDpwFpgO/Dxegd18jOzzAVBX0bd3oh4HDhuiPevqXkdwEWjOa6Tn5llLoCBFF3aIjn5mVku0lzPK5KTn5llLoCBBl8l3snPzHKR/Y0u2XLyM7PMBeFrfmZWPhHQ19i5z8nPzPIgBoaccdY4nPzMLHMBVNzyM7MycsvPzEqnepOzk5+ZlUwAfdHY66Y4+ZlZ5gIx0OCLRjn5mVkuKuFur5mVjK/5mVlJiQFf8zOzsqmu5OzkZ2YlEyF6o73oMEbk5DeE3p3ikrMOo6+3jYF++MAZPZz3+Q1Fh5WJLy++nw+843lefX0S51x1TtHhZKZV6wXQtWgLF3y9m/a24M4bZnLTFfsVHVIqlQa/5pdbu1TSXEn3S3pK0pOSPjNEGUm6XNJaSY9LWpBXPKPRMSH4xs3Pcs29a7j6njUsf2AfnloxueiwMvHzVYfzqZ+cUXQYmWvVerW1BRdd9if+8aOH8HeLDueDizczb/7O+l8sWHXAoy3VVpQ8z9wPXBIR7wROAC6SdOSgMqcB85PtfODqHONJTYJJU6qrkfX3iYE+ocb+Ryy1R58/gJ4dE4oOI3OtWq/Dj9tO93Pj2fDCBPr72njg9hksPKWn6LBSqA54pNmKktuZI2J9RKxMXm8FnqL6BPVai4Fro+phYIak2XnFNBoDA3DhyYdzzruO5rgTt3LEgu1Fh2QltO/+fbzSPf6N/Y3rO+ic3VdgROnsHvBIsxVlTM4s6WCqT196ZNBHc4AXa/bX8ecJshDt7XD1vWu4bsVq1qyazHO/n1h0SFZCQ/U4Gnx1+DcMhFJtRck9+UmaCtwCfDYitgz+eIiv/NlPK+l8ScslLX9l00AeYQ5r6vQBjlm4jWX37zOm5zWDaktv1gG9b+x3zu5j04aOAiNKJxB9MS7VVpRck5+kDqqJ77qIuHWIIuuAuTX7BwLdgwtFxJKI6IqIrln75j98vnlTO9t6qufZtUOsfHAf5h62K/fzmg22ZtVk5hzSy35zdzGuo8KixZt5+O7pRYdVVzMMeOSWdiUJ+D7wVER8e5hidwAXS7oReC/QExHr84oprVdf6uCbn5lHpSIqFTjxI5s54UODG63N6dK/vpeug7uZMXknSz/3Y753fxe3P/rOosPaa61ar8qAuPJLc7js+j/Q1g533ziT559u/EswQbFd2jTybHO+H/gY8DtJq5L3vgjMgzeetr4UOB1YC2wHPp5jPKkdeuROrrrn6aLDyMWXbjm56BBy0ar1Alh23zSW3Tet6DBGrbQzPCLiIYa+pldbJoCL8orBzIoRQcPP7W3s6MysKVUHPNpTbfWknDCxSFKPpFXJ9uV6x/X0NjPLRYaDGbsnTKyUtA+wQtI9EbF6ULkHI+LDaQ/q5GdmmQuU2WKmySDo+uT1Vkm7J0wMTn6j4m6vmeUij1tdRpgwAbBQ0mOS7pR0VL1jueVnZpmrPrc3dWLrlLS8Zn9JRCwZXKjOhImVwEERsU3S6cBtVNcMGJaTn5nlQKNZxn5jRHSNeLQ6EyZqk2FELJV0laTOiNg43DGd/Mwsc9VHV2YzGyvNhAlJ+wMvRURIOp7qJb1NIx3Xyc/MMheh0XR760kzYeJs4EJJ/cAO4NzkPuJhOfmZWS6yusk55YSJK4ArRnNcJz8zy1x1Pb/yzu01s9LyoyvNrISqt7q45WdmJbN7bm8jc/Izs1yUdkkrMyuv6pJW7vaaWQn5mp+ZlU51VRd3e82sZKrT25z8zKx03PIzs5LyDA8zKx2P9ubg6ccnc8oBxxYdRuZWdF9ddAg2SieceXbRIeTntL0/hLu9ZlY6WT7DIy9OfmaWuQD63fIzszJyt9fMyifc7TWzEvJipmZWWm75mVnpeDFTMyulQPRXPOBhZiXka35mVj7hbq+ZlZCv+ZlZaTn5mVnpBGLAAx5mVkYe8DCz0okmGPBo7HapmTWtCKXa6pE0V9L9kp6S9KSkzwxRRpIul7RW0uOSFtQ7rlt+ZpaDTBc26AcuiYiVkvYBVki6JyJW15Q5DZifbO8Frk7+Oyy3/MwsF1m1/CJifUSsTF5vBZ4C5gwqthi4NqoeBmZImj3Scd3yM7PMRcBAJXXLr1PS8pr9JRGxZKiCkg4GjgMeGfTRHODFmv11yXvrhzupk5+Z5WIUo70bI6KrXiFJU4FbgM9GxJbBHw/xlRjpeE5+Zpa5gFRd2rQkdVBNfNdFxK1DFFkHzK3ZPxDoHumYvuZnZjmoDnik2eoeSRLwfeCpiPj2MMXuAM5LRn1PAHoiYtguL7jlZ2Y5iRE7naPyfuBjwO8krUre+yIwr3qeuAZYCpwOrAW2Ax+vd1Anv2F0LdrCBV/vpr0tuPOGmdx0xX5Fh7TXeneKS846jL7eNgb64QNn9HDe5zcUHVYmWrVueqWPyd96Gb3WDxK9p06j98wZRYeVSlbd3oh4iKGv6dWWCeCi0Rw3t+QnaS5wLbA/UKE6gvO/B5VZBNwO/DF569aI+FpeMaXV1hZcdNmf+IdzD2Xj+g6+u/QZHr5rOi88M7Ho0PZKx4TgGzc/y6QpFfr74HNnzuc9J23hne/eXnRoe61l69YudnxiXyqHTYTtFaZ++kX6F0ymMm980ZGNqDra29hX1fJs+aW5MRHgwYj4cI5xjNrhx22n+7nxbHhhAgAP3D6Dhaf0NH3yk2DSlAoA/X1ioE+osWcgpdaqdYuZ44iZyV/TyW1U5o2nbWN/wyc/yLTbm4vckl9ysXF98nqrpN03Jg5Ofg1n3/37eKX7zf+5Nq7v4IgFTd6CSAwMwMWnHE73c+P5yH/d2DL1gtauG4Be6qP92V30H9Ec/whnOdqbhzFpl45wYyLAQkmPSbpT0lHDfP98ScslLe9jV56hJuf78/ca/V+xtNrb4ep713DditWsWTWZ537fHH+R0mjlurGjwpRLN7Dj/E6Y3NjdSaguaZXVDI+85P6nWOfGxJXAQRFxDPBd4LahjhERSyKiKyK6OpiQa7xQbenNOqD3jf3O2X1s2tCR+3nH0tTpAxyzcBvL7t+n6FAy13J16w8mX7qe3kVT6X//1KKjSS1SbkXJNfnVuzExIrZExLbk9VKgQ1JnnjGlsWbVZOYc0st+c3cxrqPCosWbefju6UWHtdc2b2pnW087ALt2iJUP7sPcw/JvSY+Flq1bBJO+8zKVuePpPettRUeTXkBUlGorSp6jvXVvTJS0P/BSRISk46km4015xZRWZUBc+aU5XHb9H2hrh7tvnMnzTzd/F+rVlzr45mfmUamISgVO/MhmTvjQ4MZ4c2rVurWv3sn4+7YycPB4pl78AgA7/3Zf+t8zpeDI6mv0a355jvamuTHxbOBCSf3ADuDc5H6dwi27bxrL7ptWdBiZOvTInVx1z9NFh5GLVq3bwFGT6Fl6WNFh7JHG+Js8vGGTn6TvMkKXPCI+PdKBU96YeAVwRZ0YzazJZD23Nw8jtfyWj/CZmdnwAmjW5BcRP6rdlzQlIl7PPyQzawWN3u2tO9oraaGk1VRXT0XSMZKuyj0yM2ti6UZ6ixztTXOry3eAU0hGYSPiMeDEHGMys1bQ4Df6pRrtjYgX9dZpDwP5hGNmLSGae8BjtxclvQ8ISeOBT5N0gc3MhtXs1/yAC6iukzUH+BNwLKNcN8vMykgpt2LUbflFxEbgo2MQi5m1kkrRAYwszWjvoZJ+LukVSS9Lul3SoWMRnJk1qd33+aXZCpKm23s9cBMwGzgAuBm4Ic+gzKz5RaTbipIm+SkifhwR/cn2Exr+UqaZFa5Zb3WRNDN5eb+kLwA3Ug31HOCXYxCbmTWzJr7VZQXVZLe7Bp+s+SyAr+cVlJk1PzV4/3Ckub2HjGUgZtZCQlDg1LU0Us3wkHQ0cCTwxoqeEXFtXkGZWQto1pbfbpK+AiyimvyWAqcBD1F9Jq+Z2dAaPPmlGe09G/hLYENEfBw4BsbgKUJm1tyadbS3xo6IqEjqlzQNeBnwTc5mNrwmWMw0TctvuaQZwL9SHQFeCfw2z6DMrPkp0m11jyP9IJld9sQwny+S1CNpVbJ9OU18aeb2/o/k5TWSfgVMi4jH0xzczEosuy7tD6k+62ekcYYHI+LDoznoSDc5Lxjps4hYOZoTmVm5ZHWfX0T8WtLB2RztTSO1/L41wmcBnJRxLKkMzJ9Az+XN+Si/ka0qOoDcnHLAsUWHkIvprC06hMaW/ppfp6TaB6YtiYglozzbQkmPAd3A30fEk/W+MNJNzh8c5cnNzKpGN5K7MSK69uJsK4GDImKbpNOB24D59b6UZsDDzGz0xuhWl4jYEhHbktdLgQ5JnfW+l2qGh5nZaGmMFjOVtD/wUkSEpOOpNuo21fuek5+Z5SOjAQ9JN1CdZdYpaR3wFaADICKuoToR40JJ/cAO4NyI+isFppneJqrL2B8aEV+TNA/YPyJ8r5+ZDSntPXxpRMTf1Pn8Cqq3woxKmmt+VwELgd0BbAWuHO2JzKxkGnwZ+zTd3vdGxAJJjwJExGvJIyzNzIbX4AsbpEl+fZLaSaoiaRYN/1wmMyta0y5mWuNy4GfA2yVdSvXi4j/mGpWZNbcYu9HePZVmbu91klZQXdZKwJkR8VTukZlZc2v2ll8yursd+HntexHxQp6BmVmTa/bkR/VJbbsfZDQROARYAxyVY1xm1uSa/ppfRPxF7X6y2ssnhyluZtYURj3DIyJWSnpPHsGYWQtp9pafpM/V7LYBC4BXcovIzJpfK4z2AvvUvO6neg3wlnzCMbOW0cwtv+Tm5qkR8fkxisfMWoBo4gEPSeMion+k5ezNzIbVrMmP6hPaFgCrJN0B3Ay8vvvDiLg159jMrFlluKpLXtJc85tJdWHAk3jzfr8AnPzMbHhNPODx9mSk9wneTHq7NXhON7OiNXPLrx2YyluT3m4NXi0zK1yDZ4mRkt/6iPjamEXSQPRKH5O/9TJ6rR8kek+dRu+ZM4oOa6/17hSXnHUYfb1tDPTDB87o4bzPbyg6rMx0LdrCBV/vpr0tuPOGmdx0xX5Fh5SJpqxXRg8nytNIyW9MlliVNBH4NTAhieenEfGVsTj3sNrFjk/sS+WwibC9wtRPv0j/gslU5jX3Gq4dE4Jv3Pwsk6ZU6O+Dz505n/ectIV3vnt70aHttba24KLL/sQ/nHsoG9d38N2lz/DwXdN54ZmJRYe2V5q5Xo3e7R1pGfu/HKMYdgEnRcQxwLHAqZJOGKNzDylmjqsmPoDJbVTmjadtY3+RIWVCgklTqleh+/vEQJ9QcauIZ+rw47bT/dx4Nrwwgf6+Nh64fQYLT+kpOqy91tT1GqNHV+6pYZNfRLw6FgFE1bZktyPZGubfDL3UR/uzu+g/ovH/pU1jYAAuPPlwznnX0Rx34laOWND8rT6Afffv45XuN1vmG9d30Dm7r8CIstHM9VIl3VaUhnhouaR2SauAl4F7IuKRQZ+fL2m5pOX9PWP4l3VHhSmXbmDH+Z0wuSH+qPZaeztcfe8arluxmjWrJvPc71sjqQ/Vgq3/8MLG17T1Stvqa8SW31iKiIGIOBY4EDhe0tGDPl8SEV0R0TVu+uSxCao/mHzpenoXTaX//VPH5pxjaOr0AY5ZuI1l9+9Tv3AT2Li+g1kH9L6x3zm7j00bOgqMKBvNWi+NYitKQyS/3SJiM/AAcGrBgTDpOy9TmTue3rPeVmgoWdq8qZ1tPe0A7NohVj64D3MP21VwVNlYs2oycw7pZb+5uxjXUWHR4s08fPf0osPaa01drwZv+Y16Pb+sJU+D64uIzZImAScD/1xkTO2rdzL+vq0MHDyeqRdXV+vf+bf70v+eKUWGtddefamDb35mHpWKqFTgxI9s5oQPbSk6rExUBsSVX5rDZdf/gbZ2uPvGmTz/dPN36Zu5Xo0+2lt48gNmAz9KVpBpA26KiF8UGdDAUZPoWXpYkSHk4tAjd3LVPU8XHUZult03jWX3TSs6jMw1bb2c/EYWEY8DxxUdh5llqAkWM22oa35m1kIyuuYn6QeSXpb0xDCfS9LlktZKejztMnxOfmaWC0W6LYUfMvIg6GnA/GQ7H7g6zUGd/MwsHxm1/CLi18BIky4WA9cmEyYeBmZIml3vuIVf8zOz1jSK0d5OSctr9pdExJJRnGoO8GLN/rrkvfUjfcnJz8yyF4xmMdONEdG1F2fbo2X3nPzMLHNj/ACjdcDcmv0Dge56X/I1PzPLx9jN8LgDOC8Z9T0B6ImIEbu84JafmeVEGa3AIOkGYBHVa4PrgK9QXf2JiLgGWAqcDqwFtgMfT3NcJz8zy16G83Yj4m/qfB7ARaM9rpOfmeXCc3vNrJQafXqbk5+Z5cMtPzMrnfRT1wrj5Gdm+XDyM7OyGeObnPeIk5+Z5UKVxs5+Tn5mlr2Cn8+RhpOfmeXCt7qYWTm55WdmZeQBDzMrnwAyWtggL02X/Nqf2cX009cWHUbm3n3+hUWHkJtOflN0CFYAX/Mzs9LxfX5mVk4R7vaaWTm55Wdm5eTkZ2Zl5JafmZVPAAONnf2c/MwsF275mVk5ebTXzMrILT8zKx8vaWVmZSRAHvAwszKSr/mZWem422tm5dT4c3vbig7AzFqTIt2W6ljSqZLWSFor6QtDfL5IUo+kVcn25XrHdMvPzPKRUctPUjtwJfAhYB2wTNIdEbF6UNEHI+LDaY/r5Gdm2YtMR3uPB9ZGxB8AJN0ILAYGJ79RcbfXzPIRKbf65gAv1uyvS94bbKGkxyTdKemoegd1y8/McjGKW106JS2v2V8SEUtqDzXEdwYffCVwUERsk3Q6cBswf6STOvmZWT7SJ7+NEdE1wufrgLk1+wcC3W89VWypeb1U0lWSOiNi43AHdbfXzLIXQCXlVt8yYL6kQySNB84F7qgtIGl/SUpeH081t20a6aBu+ZlZ5kRkNsMjIvolXQzcBbQDP4iIJyVdkHx+DXA2cKGkfmAHcG7EyAE4+Q2ja9EWLvh6N+1twZ03zOSmK/YrOqRMfHnx/XzgHc/z6uuTOOeqc4oOJ1Ot+ps1bb0q2T27MiKWAksHvXdNzesrgCtGc8zcur2SJkr6bTL68qSkrw5RZtQ3Jo6Ftrbgosv+xD9+9BD+btHhfHDxZubN31l0WJn4+arD+dRPzig6jMy16m/WtPXKttubizyv+e0CToqIY4BjgVMlnTBEuQcj4thk+1qO8aR2+HHb6X5uPBtemEB/XxsP3D6Dhaf0FB1WJh59/gB6dkwoOozMtepv1sz1UkSqrSi5Jb+o2pbsdiRbY0/2S+y7fx+vdI9/Y3/j+g46Z/cVGJHV06q/WVPXa/eze+ttBcl1tFdSu6RVwMvAPRHxyBDFRnVj4ljQEHcVNfgc7dJr1d+seeuVMvEVWJlcBzwiYgA4VtIM4GeSjo6IJ2qKpLoxUdL5wPkAE5mcZ8hA9V/XWQf0vrHfObuPTRs6cj+v7blW/c2atl5N8PS2MbnPLyI2Aw8Apw56f8vurnEymtMhqXOI7y+JiK6I6Oog/+tVa1ZNZs4hvew3dxfjOiosWryZh++envt5bc+16m/WzPVq9Gt+ubX8JM0C+iJis6RJwMnAPw8qsz/wUkRE2hsTx0JlQFz5pTlcdv0faGuHu2+cyfNPTyw6rExc+tf30nVwNzMm72Tp537M9+7v4vZH31l0WHutVX+zpq5Xg/fP8+z2zgZ+lCxH0wbcFBG/2NsbE8fKsvumsey+aUWHkbkv3XJy0SHkplV/s6asVwCVhvirPKzckl9EPA4cN8T7e3Vjopk1g8ZfydkzPMwsH05+ZlY6AQwUOH0jBSc/M8tBQDj5mVkZudtrZqVT5tFeMys5t/zMrJSc/MysdCJgYKDoKEbk5Gdm+XDLz8xKycnPzMonPNprZiUUEL7J2cxKydPbzKx0IjJ9dGUenPzMLB8e8DCzMgq3/MysfLyYqZmVkRc2MLMyCiAafHrbmDy60sxKJpLFTNNsKUg6VdIaSWslfWGIzyXp8uTzxyUtqHdMt/zMLBeRUbc3eQLklcCHgHXAMkl3RMTqmmKnAfOT7b3A1cl/h+WWn5nlI7uW3/HA2oj4Q0T0AjcCiweVWQxcG1UPAzMkzR7poE3X8tvKaxvvjZ8+P0an6wQ2jsmZvvfTMTlNjbGr29hyvbJx0N58eSuv3XVv/LQzZfGJkpbX7C+JiCU1+3OAF2v21/HnrbqhyswB1g930qZLfhExa6zOJWl5RHSN1fnGUqvWzfVqDBFxaoaH01Cn2IMyb+Fur5k1unXA3Jr9A4HuPSjzFk5+ZtbolgHzJR0iaTxwLnDHoDJ3AOclo74nAD0RMWyXF5qw2zvGltQv0rRatW6uV4uJiH5JFwN3Ae3ADyLiSUkXJJ9fAywFTgfWAtuBj9c7rqLBp6CYmeXB3V4zKyUnPzMrpdInP0lzJd0v6SlJT0r6zBBlRj11pmgp67VIUo+kVcn25SJizYKkiZJ+K+mxpL5fLTqm0UpTh1b6zYrmAQ/oBy6JiJWS9gFWSLpnb6fONIA09QJ4MCI+XEB8WdsFnBQR2yR1AA9JujO5279ZpK1Dq/xmhSp9yy8i1kfEyuT1VuApqneG1xr11JmipaxXy0h+m23JbkeyNdVoXivUoZmUPvnVknQwcBzwyKCPhps60xRGqBfAwqSbdaeko8Y2smxJape0CngZuCcihqpvQ0tZh5b5zYrk5JeQNBW4BfhsRGwZ/PEQX2mKf5Hr1GslcFBEHAN8F7htjMPLVEQMRMSxVO/uP17S0QWHNGop6tBSv1mRnPyA5PrKLcB1EXHrEEVGPXWmEdSrV0Rs2d3NioilQIektJPRG1ZEbAYeALKcXzqmhqtDq/5mRSh98pMk4PvAUxHx7WGKjXrqTNHS1EvS/kk5JB1P9f+HTWMXZXYkzZI0I3k9CTgZ+H2hQY1Smjq00m9WNI/2wvuBjwG/S661AHwRmAd7PnWmAaSp19nAhZL6gR3AudG8U35mAz9KFr5sA26KiF8UHNNoDVmHQdO4Wuk3K5Snt5lZKZW+22tm5eTkZ2al5ORnZqXk5GdmpeTkZ2al5OTXgiQNJCt+PCHpZkmT9+JYP5R0dvL63yQdOULZRZLetwfneG6oG3WHe39QmW0jfT5E+X+S9PejjdFaj5Nfa9oREcdGxNFAL3BB7YfJfWSjFhGfGGJVmFqLgFEnP7MiOPm1vgeBw5JW2f2Srqd643O7pH+RtCxZo/CT8MbahVdIWi3pl8Dbdx9I0gOSupLXp0pamUyw//dk8YQLgP+ZtDo/kMxYuCU5xzJJ70++u6+kuyU9Kul7DD13+i0k3SZpRbLO3fmDPvtWEsu/S5qVvPcfJP0q+c6Dko7I5E/TWoZneLQwSeOorkX4q+St44GjI+KPSQLpiYj3SJoA/D9Jd1Nd/eVw4C+A/YDVwA8GHXcW8K/AicmxZkbEq5KuAbZFxDeTctcD/ysiHpI0j+oDaN4JfAV4KCK+JukM4C3JbBj/LTnHJGCZpFsiYhMwBVgZEZeourDnV4CLqT7w54KIeEbSe4GrgJP24I/RWpSTX2uaVDOl7UGqc3zfB/w2Iv6YvP+fgHftvp4HTKe6WOuJwA0RMQB0S7pviOOfAPx697Ei4tVh4jgZODKZigowTdWFVU8Ezkq++0tJr6Wo06cl/VXyem4S6yagAvyf5P2fALcmK9m8D7i55twTUpzDSsTJrzXtSJZFekOSBF6vfQv4VETcNajc6dRfrkspykD1ssrCiNgxRCyp51VKWkQ1kS6MiO2SHgAmDlM8kvNuHvxnYFbL1/zK6y6qE+Q7ACS9Q9IU4NfAuck1wdnAB4f47m+A/yjpkOS7M5P3twL71JS7m2oXlKTcscnLXwMfTd47DXhbnVinA68lie8Iqi3P3dqoTvYH+C9Uu9NbgD9K+s/JOSTpmDrnsJJx8iuvf6N6PW+lpCeA71HtCfwMeAb4HdVnlfzfwV+MiFeoXqe7VdJjvNnt/DnwV7sHPIBPA13JgMpq3hx1/ipwoqSVVLvfL9SJ9VfAOEmPA18Hap9p8TpwlKQVVK/pfS15/6PAf0/ie5LqowjM3uBVXcyslNzyM7NScvIzs1Jy8jOzUnLyM7NScvIzs1Jy8jOzUnLyM7NS+v8edUnhDdMTyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the labels\n",
    "target_names = ['2.0','2.5','3','3.5']\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification report:\\n\", classification_report(true_labels, predictions, target_names = target_names, digits = 3))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Confusion Matrix: \\n\")\n",
    "# Compute confusion matrix\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = target_names)\n",
    "disp = disp.plot()\n",
    "plt.savefig(filename+\"_confusion_matrix\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1, stop = 100, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 3, verbose=1, n_jobs = -1)\n",
    "\n",
    "print(rf_random)\n",
    "# Fit the random search model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import time\n",
    "start = time.time() # Data augmentation takes roughly 10 minutes\n",
    "\n",
    "# fit the model \n",
    "rf_random.fit(X_Generated, y_Generated)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken to finish fitting all models: \", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16304/2964965443.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_random' is not defined"
     ]
    }
   ],
   "source": [
    "parameters = rf_random.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###################################\n",
    "### Evaluate the model and plot the prediction results ###\n",
    "###################################\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "filepath = filename +\".h5\"\n",
    "model = load_model(filepath, compile=True)\n",
    "\n",
    "# show the confusion matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "true_labels = y_test\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Set the labels\n",
    "target_names = ['2.0','2.5','3','3.5']\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification report:\\n\", classification_report(true_labels, predictions, target_names = target_names, digits = 3))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Confusion Matrix: \\n\")\n",
    "# Compute confusion matrix\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = target_names)\n",
    "disp = disp.plot()\n",
    "plt.savefig(filename+\"_confusion_matrix\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"from keras.utils import plot_model\\n\",\n",
    "    \"plot_model(CNN_model,\\n\",\n",
    "    \"    to_file=\\\"CNN_model3.png\\\",\\n\",\n",
    "    \"    show_shapes=True,\\n\",\n",
    "    \"    show_layer_names=True,\\n\",\n",
    "    \"    rankdir=\\\"TB\\\",\\n\",\n",
    "    \"    expand_nested=False,\\n\",\n",
    "    \"    dpi=96,\\n\",\n",
    "    \")\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "######################################\n",
    "### Random Forest Model Evaluation ###\n",
    "######################################\n",
    "import time\n",
    "start = time.time() # Data augmentation takes roughly 10 minutes\n",
    "\n",
    "stratifiedKFold = StratifiedKFold(n_splits = 3, random_state = 1, shuffle = True)\n",
    "y_pred = cross_val_predict(model, X_Generated, y_Generated, n_jobs = 5, cv = stratifiedKFold)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_Generated, y_pred, digits = 3))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken to finish fitting all models: \", (end - start))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0233f353920c16d2923bd58a39b232e6099f553d9e9646e45ab07e0c0ed942a3"
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
